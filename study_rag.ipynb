{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_RAG_INSTRUCTIONS = \"\"\"\n",
    "You are an intelligent assistant designed to help users track and reflect on their daily lives through their conversation history. You have access to prior conversation summaries stored in JSON files (e.g., \"conversation_250111.json\"). These files contain key points from the user's day-to-day conversations, including activities, preferences, feelings, and notable events.\n",
    "\n",
    "Your primary goal is to:\n",
    "1. Retrieve relevant information from past conversation files to provide meaningful context during the current conversation.\n",
    "2. Proactively bring up recurring patterns, habits, or topics the user often mentions, and ask thoughtful questions or make observations based on this context (e.g., \"Youâ€™ve been eating spicy food a lot lately, is your stomach feeling okay?\").\n",
    "3. Offer a personalized and engaging conversational experience by remembering and referencing specific details about the user.\n",
    "\n",
    "Keep your tone friendly, empathetic, and natural. If no relevant context exists in the conversation history, ask open-ended questions to learn more about the user's recent experiences.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "name=\"diary writing assistant\",\n",
    "instructions=\"\"\"\n",
    "ë„ˆëŠ” ì‚¬ìš©ìžì™€ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ \"melissa\"ì•¼. \n",
    "        \n",
    "ëŒ€í™” ë°©ì‹:\n",
    "        1. í˜„ìž¬ ì‚¬ìš©ìžì˜ ë§ì— ë¨¼ì € ìžì—°ìŠ¤ëŸ½ê²Œ ë°˜ì‘í•´\n",
    "        2. ë§Œì•½ ê³¼ê±° ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê´€ì„±ì´ ìžˆë‹¤ë©´, ê·¸ ë‚´ìš©ì„ ìžì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´\n",
    "        3. í˜„ìž¬ ëŒ€í™” ì£¼ì œë‚˜ ì‚¬ìš©ìžì˜ ê´€ì‹¬ì‚¬ë¥¼ ê³ ë ¤í•´ì„œ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•´\n",
    "        \n",
    "ì£¼ì˜ì‚¬í•­:\n",
    "        - ë°˜ë§ë¡œ ëŒ€í™”í•´\n",
    "        - ê³¼ê±° ëŒ€í™”ëŠ” ìžˆì„ ë•Œë§Œ ì–¸ê¸‰í•˜ê³ , ì—†ìœ¼ë©´ í˜„ìž¬ ëŒ€í™”ì—ë§Œ ì§‘ì¤‘í•´\n",
    "        - ë‚ ì§œ ìžˆìœ¼ë©´ \"ë©°ì¹  ì „ì—\", \"ì €ë²ˆ ì£¼ì—\" ê°™ì´ ìžì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•´\n",
    "        - ë‹µë³€ì€ ê°„ê²°í•˜ê²Œ í•˜ë˜, ê¸°ê³„ì ì´ì§€ ì•Šê²Œ í•´\n",
    "        - í•­ìƒ í¥ë¯¸ë¡œìš´ ìƒˆ ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´\n",
    "\"\"\",\n",
    "model=\"gpt-4o-mini\",\n",
    "tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=3, failed=0, in_progress=0, total=3)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"DIARY_ASSISTANT\")\n",
    "\n",
    "file_paths = [\"summary/summary_250111.json\", \"summary/summary_250112.json\", \"summary/summary_250113.json\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "assistant_id=assistant.id,\n",
    "tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_file = client.files.create(\n",
    "file=open(\"summary/summary_250111.json\", \"rb\"), purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_CUyapbSBOtIA8Gygxi78GmNl'])\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "messages=[\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"ë‚˜ ì˜¤ëŠ˜ ë”¸ê¸° ë¹µ ë¨¹ì—ˆì–´ì–´\",\n",
    "    \"attachments\": [\n",
    "      { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "    ],\n",
    "  }\n",
    "]\n",
    ")\n",
    "\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > file_search\n",
      "\n",
      "\n",
      "assistant > ìµœê·¼ì— ë”¸ê¸°ê°€ ë“¤ì–´ê°„ í¬ë¦¼ ëª¨ì¹´ë²ˆì„ ì¢‹ì•„í•œë‹¤ê³  í•˜ì…¨ëŠ”ë°, ì˜¤ëŠ˜ ë¨¹ì€ ë”¸ê¸° ë¹µë„ ê·¸ëŸ° ì¢…ë¥˜ì˜€ë‚˜ìš”? ë”¸ê¸°ê°€ ë§Žì´ ë“¤ì–´ê°”ë‚˜ìš”, ì•„ë‹ˆë©´ í¬ë¦¼ì´ëž‘ í•¨ê»˜ ë“¤ì–´ê°„ ë¹µì´ì—ˆë‚˜ìš”? ðŸ“[0]\n",
      "[0] summary_250112.json\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler, OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "      print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_tool_call_created(self, tool_call):\n",
    "      print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "  @override\n",
    "  def on_message_done(self, message) -> None:\n",
    "      # print a citation to the file searched\n",
    "      message_content = message.content[0].text\n",
    "      annotations = message_content.annotations\n",
    "      citations = []\n",
    "      for index, annotation in enumerate(annotations):\n",
    "          message_content.value = message_content.value.replace(\n",
    "              annotation.text, f\"[{index}]\"\n",
    "          )\n",
    "          if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "              cited_file = client.files.retrieve(file_citation.file_id)\n",
    "              citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "      print(message_content.value)\n",
    "      print(\"\\n\".join(citations))\n",
    "\n",
    "\n",
    "# Then, we use the stream SDK helper\n",
    "# with the EventHandler class to create the Run\n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=_DEFAULT_RAG_INSTRUCTIONS,\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melissa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
